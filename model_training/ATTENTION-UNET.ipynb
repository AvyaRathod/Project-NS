{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88c8f888-4eb5-438e-8428-0d6f9280aa70",
    "_uuid": "3cf23599bb2587214d3f8b50d3b512bb025159f1"
   },
   "source": [
    "### Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b324c96-b92c-4c71-835a-cc6adb1c7a0c",
    "_uuid": "9d65868c23446ed123810c4187c0e598ce01c652"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers import BatchNormalization, add, Activation, UpSampling2D, multiply  \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "BATCH_SIZE = 16 # the higher the better\n",
    "IMG_WIDTH = 128 # for faster computing on kaggle\n",
    "IMG_HEIGHT = 128 # for faster computing on kaggle\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = './stage1_train/'\n",
    "TEST_PATH = './stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2464b8e-77ba-44b1-8c78-06b1e690910d",
    "_uuid": "a3c37b92fa214f1be75ac3630927555ff40674b2"
   },
   "source": [
    "###  1. Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb7da2b8-5921-4769-9bee-afab2135472d",
    "_uuid": "2ff390c2a99e276c65e34d9ed61208347cacafe2"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6db52ac-98df-4e0f-bab2-b83565c0fde2",
    "_uuid": "ef50f72d80920e9b53c73919994199c0c9a8c955"
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f70481c-7b7b-4f60-8d11-e0e36030697c",
    "_uuid": "1593b0eb0503758424ce1ec5ded8d59557d4d1df"
   },
   "source": [
    "###  2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e78cfea-5120-4c18-80a0-fd09964e024d",
    "_uuid": "7448169cf1949461f30735a89f96b4c4003dccea"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Creating the training Image and Mask generator\n",
    "image_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n",
    "mask_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n",
    "\n",
    "# Keep the same seed for image and mask generators so they fit together\n",
    "\n",
    "image_datagen.fit(X_train[:int(X_train.shape[0]*0.9)], augment=True, seed=seed)\n",
    "mask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.9)], augment=True, seed=seed)\n",
    "\n",
    "x=image_datagen.flow(X_train[:int(X_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "# Creating the validation Image and Mask generator\n",
    "image_datagen_val = image.ImageDataGenerator()\n",
    "mask_datagen_val = image.ImageDataGenerator()\n",
    "\n",
    "image_datagen_val.fit(X_train[int(X_train.shape[0]*0.9):], augment=True, seed=seed)\n",
    "mask_datagen_val.fit(Y_train[int(Y_train.shape[0]*0.9):], augment=True, seed=seed)\n",
    "\n",
    "x_val=image_datagen_val.flow(X_train[int(X_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y_val=mask_datagen_val.flow(Y_train[int(Y_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6a85b26-695e-4975-b22f-80a79209c370",
    "_uuid": "22785cbdcdf3e7712ba2423a90869e44bd74e28c"
   },
   "outputs": [],
   "source": [
    "# Checking if the images fit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "imshow(x.next()[0].astype(np.uint8))\n",
    "plt.show()\n",
    "imshow(np.squeeze(y.next()[0].astype(np.uint8)))\n",
    "plt.show()\n",
    "imshow(x_val.next()[0].astype(np.uint8))\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_val.next()[0].astype(np.uint8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae011253-08b8-44db-8be9-c1092e171553",
    "_uuid": "17f9af12f2fc93a2e57c3cfdc3c122f97f1fa7e4"
   },
   "source": [
    "###  3. Creating the U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(x,y)\n",
    "val_generator = zip(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b9b4831-27b2-4a9d-a371-b31ef3a423e1",
    "_uuid": "1f14f1661097ea33049514f442492e0d4d44480c"
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def jacard_coef(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0)/(K.sum(y_true_f)+K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x,filter_size,size,dropout, batch_norm=False):\n",
    "    conv = Conv2D(size, (filter_size,filter_size), activation='elu', kernel_initializer='he_normal', padding=\"same\")(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=3)(conv)\n",
    "\n",
    "    conv = Conv2D(size, (filter_size,filter_size), activation='elu', kernel_initializer='he_normal', padding=\"same\")(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=3)(conv)\n",
    "\n",
    "    if dropout > 0:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def repeat_elem(tensor, rep):\n",
    "\n",
    "    return Lambda(lambda x, repnum : K.repeat_elements(x,repnum,axis=3),arguments={'repnum':rep})(tensor)\n",
    "\n",
    "def gating_signal(input,out_size,batch_norm=False):\n",
    "    x = Conv2D(out_size,(1,1), activation='elu', kernel_initializer='he_normal', padding='same')(input)\n",
    "    if batch_norm is True:\n",
    "        x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def attention_block(x,gating,inter_shape):\n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(gating)\n",
    "\n",
    "    #Getting x to the same shape as the gating signal\n",
    "    theta_x = Conv2D(inter_shape,(2,2),kernel_initializer='he_normal',strides=(2,2),padding='same')(x)\n",
    "    shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "    #getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_g = Conv2D(inter_shape,(1,1),kernel_initializer='he_normal',padding='same')(gating)\n",
    "    upsample_g = Conv2DTranspose(inter_shape,(3,3),strides=(shape_theta_x[1] // shape_g[1],shape_theta_x[2]//shape_g[2]), padding='same')(phi_g)\n",
    "\n",
    "    concat_xg = add([upsample_g,theta_x])\n",
    "    act_xg = Activation('relu')(concat_xg)\n",
    "    psi = Conv2D(1,(1,1),padding='same')(act_xg)\n",
    "    sigmoid_xg = Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1],shape_x[2]//shape_sigmoid[2]))(sigmoid_xg)\n",
    "\n",
    "    upsample_psi = repeat_elem(upsample_psi,shape_x[3])\n",
    "\n",
    "\n",
    "    y = multiply([upsample_psi,x])\n",
    "\n",
    "    result = Conv2D(shape_x[3],(1,1),padding='same')(y)\n",
    "    result_bn = BatchNormalization()(result)\n",
    "    return result_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f97a2d9-a9a0-4399-bbca-198cdda087b6",
    "_uuid": "ab499cefbbe8dc514c6347fe203d87eb7974adf0"
   },
   "outputs": [],
   "source": [
    "# Build Att-U-Net model\n",
    "NUM_CLASSES = 1 \n",
    "dropout_rate=0.1 \n",
    "batch_norm=True\n",
    "FILTER_NUM = 64\n",
    "FILTER_SIZE = 3\n",
    "UP_SAMP_SIZE = 2\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "inputs = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "#Downsampling layers\n",
    "#DownRes 1, convolution +pooling\n",
    "conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate,batch_norm)\n",
    "pool_64 = MaxPooling2D(pool_size=(2,2))(conv_128)\n",
    "#DownRes 2\n",
    "conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate,batch_norm)\n",
    "pool_32 = MaxPooling2D(pool_size=(2,2))(conv_64)\n",
    "#DownRes 3\n",
    "conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "pool_16 = MaxPooling2D(pool_size=(2,2))(conv_32)\n",
    "#DownRes 4\n",
    "conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "pool_8 = MaxPooling2D(pool_size=(2,2))(conv_16)\n",
    "#DownRes 5\n",
    "conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "#Upsampling Layers\n",
    "#UpRes 6\n",
    "gating_16 = gating_signal(conv_8,8*FILTER_NUM, batch_norm)\n",
    "att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
    "up_16 = UpSampling2D(size=(UP_SAMP_SIZE,UP_SAMP_SIZE), data_format='channels_last')(conv_8)\n",
    "up_16 = concatenate([up_16,att_16], axis=3)\n",
    "up_conv_16 = conv_block(up_16,FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "#UpRes 7\n",
    "gating_32 = gating_signal(up_conv_16,4*FILTER_NUM, batch_norm)\n",
    "att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
    "up_32 = UpSampling2D(size=(UP_SAMP_SIZE,UP_SAMP_SIZE), data_format='channels_last')(up_conv_16)\n",
    "up_32 = concatenate([up_32,att_32], axis=3)\n",
    "up_conv_32 = conv_block(up_32,FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "#UpRes 8\n",
    "gating_64 = gating_signal(up_conv_32,2*FILTER_NUM, batch_norm)\n",
    "att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
    "up_64 = UpSampling2D(size=(UP_SAMP_SIZE,UP_SAMP_SIZE), data_format='channels_last')(up_conv_32)\n",
    "up_64 = concatenate([up_64,att_64], axis=3)\n",
    "up_conv_64 = conv_block(up_64,FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "#UpRes 9\n",
    "gating_128 = gating_signal(up_conv_64,FILTER_NUM, batch_norm)\n",
    "att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
    "up_128 = UpSampling2D(size=(UP_SAMP_SIZE,UP_SAMP_SIZE), data_format='channels_last')(up_conv_64)\n",
    "up_128 = concatenate([up_128,att_128], axis=3)\n",
    "up_conv_128 = conv_block(up_128,FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "#1*1 convolutional layers\n",
    "conv_final= Conv2D(NUM_CLASSES,kernel_size=(1,1))(up_conv_128)\n",
    "conv_final = BatchNormalization(axis=3)(conv_final)\n",
    "outputs = Activation('sigmoid')(conv_final) #change to softmax for multichannel\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',jacard_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d17d35a-753d-47c5-b1d7-7effa1af04a7",
    "_uuid": "a9378262b0194c0aa54df3e2ea5696b447f8ef83"
   },
   "source": [
    "###  4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cc45263-7607-4d9d-b0e0-88b3135ba60b",
    "_uuid": "440055f1d1feb25fe08f942d15257e2454d2022b"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=3, verbose=1)\n",
    "checkpointer = ModelCheckpoint('Attention_unet.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n",
    "                              epochs=1000, callbacks=[earlystopper, checkpointer],verbose=1,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e12a9f1-279f-4031-b8c5-4f825f84cc13",
    "_uuid": "168a4d55c79c92cd17a398cff13876fb0b32cdbf"
   },
   "source": [
    "###  5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ef72a295-7187-41d6-9ecf-c5ee201f000d",
    "_uuid": "f9b92b3ce2079288fe8a2ed75f3c8679ee93113f"
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('Attention_unet.h5', custom_objects={'jacard_coef': jacard_coef})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbad21c9-d1ef-4aee-9e16-8b340e38cd69",
    "_uuid": "b050929802713d41a75fc97a960ac6534e5cbde1"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c9fed3a-fa91-4957-833f-c2b8adf64743",
    "_uuid": "bf24083f20c4e618eeee2933dc1fd1a36413f8b7"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2e17c4a-e84e-4552-950d-a49e95393ed9",
    "_uuid": "b66a4b8ebd2a804d8d102436b0953183bdb4f30b"
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46ff9859-1d81-4a7b-be2a-f0421a67ad79",
    "_uuid": "b27241fd5a881fa0b17711ed71b7a99b7a9b4859"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('seg_models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "157facdb046848fa84041134b7d1f6970195bafc0d2d82199143cf51ae8c4496"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
